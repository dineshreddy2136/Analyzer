# main.py
import json
import ast
import sys
import argparse
import textwrap
from pathlib import Path
import colorsys
import hashlib
from collections import deque

# --- Configuration for Visualization ---
MODULE_COLOR_MAP = {
    "api": "#d4e1f5", "database": "#d5f5e3", "models": "#fff2cc", "utils": "#f5e1d4",
    "awsglue": "#f5e1d4", "pyspark": "#fff2cc", "pandas": "#d1e0f9", "complex_glue_job": "#f5d4f2"
}
LEVEL_COLORS = ["#ffadad", "#ffd6a5", "#fdffb6", "#caffbf", "#9bf6ff", "#a0c4ff", "#bdb2ff", "#ffc6ff"]

class GraphEnhancer:
    """
    Enhances call graphs generated by the 'nuanced' tool by performing deeper AST analysis.
    
    Key improvements:
    - Discovers nested functions missed by static analysis
    - Resolves complex method calls and function references 
    - Handles domain-specific patterns (AWS Glue, PySpark, Pandas)
    - Traces callbacks and function arguments
    """
    def __init__(self, graph_path):
        self.graph_path = Path(graph_path)
        if not self.graph_path.exists():
            print(f"Error: Graph file not found at {graph_path}", file=sys.stderr)
            sys.exit(1)
        self.graph = json.loads(self.graph_path.read_text())
        self.file_cache = {}
        self.root_package = ""
        if self.graph:
            first_key = next(iter(self.graph))
            if '.' in first_key:
                self.root_package = first_key.split('.')[0]

    def get_file_details(self, filepath):
        """
        Parse a Python file and extract AST, imports, and source lines.
        Results are cached for performance.
        """
        if filepath not in self.file_cache:
            try:
                source_code = Path(filepath).read_text()
                tree = ast.parse(source_code)
                import_map = {}
                for node in ast.walk(tree):
                    if isinstance(node, ast.ImportFrom) and node.module:
                        module_name = node.module.lstrip('.') if node.level > 0 else node.module
                        for alias in node.names:
                            import_map[alias.name] = module_name
                    elif isinstance(node, ast.Import):
                        for alias in node.names:
                            import_map[alias.name] = alias.name
                self.file_cache[filepath] = {"tree": tree, "imports": import_map, "source_lines": source_code.splitlines()}
            except Exception as e:
                print(f"Warning: Failed to parse {filepath}: {e}", file=sys.stderr)
                self.file_cache[filepath] = None
        return self.file_cache[filepath]

    class MethodCallVisitor(ast.NodeVisitor):
        def __init__(self, import_map, current_module, root_package, graph=None):
            self.import_map = import_map
            self.current_module = current_module
            self.root_package = root_package
            self.found_callees = []
            self.variable_types = {}
            self.graph = graph or {}
            # Pre-compute function name lookups for performance (O(1) instead of O(n))
            self._function_name_map = {}
            for func_name in self.graph.keys():
                simple_name = func_name.split('.')[-1]
                if simple_name not in self._function_name_map:
                    self._function_name_map[simple_name] = []
                self._function_name_map[simple_name].append(func_name)

        def _unroll_attribute(self, node):
            parts = []
            while isinstance(node, ast.Attribute):
                parts.append(node.attr)
                node = node.value
            if isinstance(node, ast.Name):
                parts.append(node.id)
                return parts[::-1]
            elif isinstance(node, ast.Subscript):
                # Handle cases like df['column'].method()
                if isinstance(node.value, ast.Name):
                    parts.append(node.value.id)
                    return parts[::-1]
            return None

        def visit_FunctionDef(self, node):
            original_vars = self.variable_types.copy()
            for arg in node.args.args:
                if arg.annotation:
                    self.variable_types[arg.arg] = ast.unparse(arg.annotation).strip()
            self.generic_visit(node)
            self.variable_types = original_vars

        def _handle_direct_function_call(self, var_name):
            """Handle direct function calls like print(), getResolvedOptions()"""
            if var_name in self.import_map:
                module_path = self.import_map[var_name]
                self.found_callees.append(f"{module_path}.{var_name}")
                return True
            return False

        def _handle_method_call_on_typed_variable(self, var_name, method_chain):
            """Handle method calls on variables with known types"""
            if var_name in self.variable_types:
                class_name = self.variable_types[var_name]
                module_name = self.import_map.get(class_name) or self.current_module
                callee_parts = [self.root_package, module_name, class_name] + method_chain
                self.found_callees.append(".".join(callee_parts))
                return True
            return False

        def _scan_for_function_references(self, node):
            """Scan function call arguments for function references with improved accuracy"""
            def _check_function_reference(name_node):
                if not isinstance(name_node, ast.Name):
                    return
                
                # Only consider it a function reference if we have evidence it's callable
                candidate_name = name_node.id
                
                # Look for matching functions in our graph (now O(1) lookup)
                if candidate_name in self._function_name_map:
                    # Additional check: prefer functions defined in current scope
                    matching_funcs = self._function_name_map[candidate_name]
                    current_scope_funcs = [f for f in matching_funcs if f.startswith(f"src.{self.current_module}")]
                    
                    # Prefer local functions over imported ones to reduce false positives
                    if current_scope_funcs:
                        self.found_callees.extend(current_scope_funcs)
                    elif len(matching_funcs) == 1:  # Only add if unambiguous
                        self.found_callees.extend(matching_funcs)

            # Check function arguments
            for arg in node.args:
                if isinstance(arg, ast.Name):
                    _check_function_reference(arg)
                elif isinstance(arg, ast.Dict):
                    # Handle dictionary arguments like {"quantity": has_valid_quantity}
                    for value in arg.values:
                        _check_function_reference(value)
            
            # Check keyword arguments
            for keyword in node.keywords:
                if isinstance(keyword.value, ast.Name):
                    _check_function_reference(keyword.value)
                elif isinstance(keyword.value, ast.Dict):
                    for value in keyword.value.values:
                        _check_function_reference(value)
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets[0], ast.Name):
                var_name = node.targets[0].id
                if isinstance(node.value, ast.Call):
                    # Track constructor calls (e.g., sc = SparkContext())
                    if isinstance(node.value.func, ast.Name):
                        self.variable_types[var_name] = node.value.func.id
                    # Track method calls that return objects (e.g., spark = glueContext.spark_session)
                    elif isinstance(node.value.func, ast.Attribute):
                        call_parts = self._unroll_attribute(node.value.func)
                        if call_parts:
                            # Try to infer the type from the method name
                            method_name = call_parts[-1]
                            if method_name in ['spark_session']:
                                self.variable_types[var_name] = 'SparkSession'
                            elif method_name.startswith('create_dynamic_frame'):
                                self.variable_types[var_name] = 'DynamicFrame'
                            elif method_name in ['toDF']:
                                self.variable_types[var_name] = 'DataFrame'
                            elif method_name in ['toPandas']:
                                self.variable_types[var_name] = 'pandas.DataFrame'
            self.generic_visit(node)

        def visit_Call(self, node):
            """
            Handles various call types and infers callees.
            Supports: direct functions, constructors, method calls, AWS Glue transforms, built-ins.
            """
            parts = self._unroll_attribute(node.func)
            if not parts:
                self.generic_visit(node)
                return
            
            var_name = parts[0]
            method_chain = parts[1:]
            
            # Try different call resolution strategies in order of preference
            handled = False
            
            # 1. Direct function calls (single part, in imports)
            if len(parts) == 1:
                handled = self._handle_direct_function_call(var_name)
            
            # 2. Method calls on typed variables 
            if not handled and method_chain:
                handled = self._handle_method_call_on_typed_variable(var_name, method_chain)
            
            # 3. Imported module/class method calls
            if not handled and var_name in self.import_map:
                module_path = self.import_map[var_name]
                if method_chain:
                    self.found_callees.append(f"{module_path}.{'.'.join(method_chain)}")
                else:
                    self.found_callees.append(f"{module_path}.{var_name}")
                handled = True
            
            # 4. AWS Glue transforms and other class method calls
            if not handled and len(parts) >= 2:
                full_call = ".".join(parts)
                self.found_callees.append(full_call)
                handled = True
            
            # 5. Builtin functions (last resort)
            if not handled and len(parts) == 1:
                self.found_callees.append(f"<builtin>.{var_name}")
            
            # 6. Scan arguments for function references (callbacks, etc.)
            self._scan_for_function_references(node)
                
            self.generic_visit(node)

    def discover_functions(self, node, parent_name, filepath, discovered_funcs):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
            full_name = f"{parent_name}.{node.name}"
            if full_name not in self.graph:
                discovered_funcs[full_name] = { "filepath": filepath, "callees": [], "lineno": node.lineno, "end_lineno": node.end_lineno }
            # Recursively search for nested functions in the entire function body
            for child_node in ast.walk(node):
                if child_node != node and isinstance(child_node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    self.discover_functions(child_node, full_name, filepath, discovered_funcs)
        elif isinstance(node, ast.ClassDef):
            full_name = f"{parent_name}.{node.name}"
            for child_node in node.body:
                self.discover_functions(child_node, full_name, filepath, discovered_funcs)

    def enhance(self):
        all_filepaths = {data['filepath'] for data in self.graph.values() if data.get('filepath')}
        for filepath in all_filepaths:
            file_details = self.get_file_details(filepath)
            if not file_details: continue
            module_name = f"{self.root_package}.{Path(filepath).stem}"
            newly_discovered_funcs = {}
            for node in file_details['tree'].body:
                self.discover_functions(node, module_name, filepath, newly_discovered_funcs)
            self.graph.update(newly_discovered_funcs)
        for function_name, data in self.graph.items():
            filepath = data.get("filepath")
            if not filepath: continue
            file_details = self.get_file_details(filepath)
            if not file_details: continue
            tree, import_map = file_details["tree"], file_details["imports"]
            current_module_name = Path(filepath).stem
            node_to_visit = find_function_node_in_ast(tree, function_name)
            if node_to_visit:
                visitor = self.MethodCallVisitor(import_map, current_module_name, self.root_package, self.graph)
                visitor.visit(node_to_visit)
                if visitor.found_callees:
                    data["callees"].extend(c for c in visitor.found_callees if c not in data["callees"])
        return self.graph

# --- Helper Functions ---
def find_function_node_in_ast(tree, full_function_name):
    parts = full_function_name.split('.')
    target_name = parts[-1]
    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)) and node.name == target_name:
            return node
    return None

def get_color_for_module(module_name):
    if module_name in MODULE_COLOR_MAP: return MODULE_COLOR_MAP[module_name]
    hash_val = int(hashlib.md5(module_name.encode()).hexdigest(), 16)
    hue = (hash_val % 360) / 360.0
    rgb = colorsys.hls_to_rgb(hue, 0.9, 0.8)
    return '#%02x%02x%02x' % (int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))

# --- THIS IS THE MISSING FUNCTION THAT HAS BEEN ADDED BACK ---
def get_code_preview(filepath, start_line, end_line, file_cache, max_lines=20):
    try:
        source_lines = file_cache[filepath]['source_lines']
        function_lines = source_lines[start_line - 1 : end_line]
        total_lines = len(function_lines)
        if total_lines > max_lines:
            preview_lines = function_lines[:max_lines]
            suffix = f"\\l... ({total_lines - max_lines} more lines)\\l"
        else:
            preview_lines = function_lines
            suffix = "\\l"
        preview_text = textwrap.dedent("\n".join(preview_lines))
        # Use HTML-style escapes for SVG tooltips
        escaped_text = preview_text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('"', '&quot;').replace("'", '&#39;').replace("\n", "<br/>")
        return escaped_text + suffix.replace("\\l", "<br/>")
    except Exception:
        return "Could not load code preview."

def save_as_dot_file(graph: dict, full_graph: dict, file_cache: dict, output_path: str, color_by_level=False, start_node=None):
    """
    Generate DOT file with code previews and improved level-based coloring.
    """
    print(f"Generating DOT file with previews...", file=sys.stderr)
    dot_lines = ['digraph CallGraph {', '  rankdir="LR";', '  node [shape=box, style="rounded,filled", fontname="Helvetica"];', '  edge [fontname="Helvetica"];']
    
    node_levels = {}
    if color_by_level and start_node:
        to_visit = deque([(start_node, 0)])  # Use deque for efficiency
        visited = {start_node}
        while to_visit:
            current, level = to_visit.popleft()  # O(1) operation
            node_levels[current] = level
            for callee in graph.get(current, {}).get("callees", []):
                if callee not in visited:
                    visited.add(callee)
                    to_visit.append((callee, level + 1))
    
    all_nodes_in_subgraph = set(graph.keys()) | {callee for data in graph.values() for callee in data.get("callees", [])}

    for node_name in all_nodes_in_subgraph:
        node_data = full_graph.get(node_name)
        attributes = {}
        attributes['label'] = f'"{node_name}"'
        
        if node_name in node_levels:
            color_index = node_levels[node_name] % len(LEVEL_COLORS)
            attributes['fillcolor'] = f'"{LEVEL_COLORS[color_index]}"'
        else:
            # Improved module name extraction to handle various naming patterns
            if '.' in node_name:
                parts = node_name.split('.')
                if len(parts) > 1 and parts[0] == 'src':
                    module_name = parts[1] if len(parts) > 1 else parts[0]
                else:
                    module_name = parts[0]
            else:
                module_name = node_name
            attributes['fillcolor'] = f'"{get_color_for_module(module_name)}"'

        if node_data:
            filepath = node_data.get("filepath", "")
            start_line, end_line = node_data.get("lineno", 0), node_data.get("end_lineno", 0)
            if filepath and start_line and end_line and file_cache.get(filepath):
                tooltip_text = get_code_preview(filepath, start_line, end_line, file_cache)
                attributes['tooltip'] = f'<{tooltip_text}>'
        
        attr_string = ", ".join([f'{k}={v}' for k, v in attributes.items()])
        dot_lines.append(f'  "{node_name}" [{attr_string}];')
    
    dot_lines.append('')
    for caller, data in graph.items():
        for callee in data.get("callees", []):
            dot_lines.append(f'  "{caller}" -> "{callee}";')
    
    dot_lines.append('}')
    Path(output_path).write_text("\n".join(dot_lines))
    print(f"âœ… DOT file saved to {output_path}", file=sys.stderr)

def get_deep_forward_trace(graph: dict, start_function: str) -> dict:
    """
    Get a deep forward trace of all functions called by start_function.
    Uses efficient queue operations for better performance.
    """
    dependency_tree = {}
    to_visit = deque([start_function])  # Use deque for O(1) pop operations
    visited = set()
    while to_visit:
        current_function = to_visit.popleft()  # O(1) instead of O(n)
        if current_function in visited: 
            continue
        visited.add(current_function)
        node_data = graph.get(current_function)
        if node_data:
            direct_callees = node_data.get("callees", [])
            dependency_tree[current_function] = direct_callees
            for callee in direct_callees:
                if callee not in visited:
                    to_visit.append(callee)
    return dependency_tree

def get_backward_trace(graph: dict, target_function: str) -> list:
    callers = []
    for function_name, data in graph.items():
        if target_function in data.get("callees", []):
            callers.append(function_name)
    return callers

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate a dependency trace for a Python function or script.")
    target_group = parser.add_mutually_exclusive_group(required=True)
    target_group.add_argument("--func", dest="target_function", help="The full name of the function to analyze")
    target_group.add_argument("--file", dest="target_file", help="The path to a Python script to analyze from its main entry point")
    parser.add_argument("--dot", help="Optional: Specify a filename to save a visual graph")
    parser.add_argument("--o", "--overview", action="store_true", help="Generate a DOT file of the entire project graph.")
    report_group = parser.add_mutually_exclusive_group()
    report_group.add_argument("--f", "--forward", action="store_true", help="Show forward dependency tracking only.")
    report_group.add_argument("--b", "--backward", action="store_true", help="Show backward dependency tracking only.")
    report_group.add_argument("--full", action="store_true", help="Show both forward and backward tracking (default).")
    args = parser.parse_args()
    
    enhancer = GraphEnhancer("src/.nuanced/nuanced-graph.json")
    enhanced_graph = enhancer.enhance()
    
    if args.target_file:
        p = Path(args.target_file)
        start_node = ".".join(p.with_suffix("").parts)
        # Allow override of forward-only for file targets
        is_forward_only = args.f if args.f else not (args.b or args.full)
        is_backward_only = args.b
        is_full_report = args.full or not (is_forward_only or is_backward_only)
    else:
        start_node = args.target_function
        is_forward_only = args.f
        is_backward_only = args.b
        is_full_report = args.full or not (is_forward_only or is_backward_only)

    # Validate that the start node exists in the graph
    if start_node not in enhanced_graph:
        print(f"Warning: Start node '{start_node}' not found in graph. Available functions:", file=sys.stderr)
        similar_funcs = [f for f in enhanced_graph.keys() if start_node.split('.')[-1] in f]
        if similar_funcs:
            print(f"  Similar functions: {similar_funcs[:5]}", file=sys.stderr)
        else:
            print(f"  Total functions in graph: {len(enhanced_graph)}", file=sys.stderr)

    if args.dot:
        graph_for_dot, color_by_level = {}, False
        if args.o:
            graph_for_dot = enhanced_graph
        else: 
            color_by_level = True
            if is_backward_only:
                callers = get_backward_trace(enhanced_graph, start_node)
                graph_for_dot = {caller: {"callees": [start_node]} for caller in callers}
            else: 
                forward_tree = get_deep_forward_trace(enhanced_graph, start_node)
                graph_for_dot = {func: {"callees": callees} for func, callees in forward_tree.items()}
                if is_full_report:
                     callers = get_backward_trace(enhanced_graph, start_node)
                     for caller in callers:
                        if caller not in graph_for_dot: 
                            graph_for_dot[caller] = {"callees": []}
                        if start_node not in graph_for_dot[caller]["callees"]:
                            graph_for_dot[caller]["callees"].append(start_node)
        save_as_dot_file(graph_for_dot, enhanced_graph, enhancer.file_cache, args.dot, color_by_level, start_node)
    
    final_report = {"start_point": start_node}
    if is_forward_only or is_full_report:
        final_report["forward_dependency_tree"] = get_deep_forward_trace(enhanced_graph, start_node)
    if is_backward_only or is_full_report:
        final_report["backward_tracking_callers"] = get_backward_trace(enhanced_graph, start_node)
    
    # Sort keys for consistent output
    print(json.dumps(final_report, indent=2, sort_keys=True))